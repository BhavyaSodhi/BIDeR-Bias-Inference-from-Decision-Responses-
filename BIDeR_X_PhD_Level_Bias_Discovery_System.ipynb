{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **BIDeR ( Bias Inference from Decision Responses):AI for Detecting Invisible Decision Bias in Everyday Systems**\n",
        "An AI that reveals hidden biases in any decision systemâ€”like college admissions, loan approvals, or job shortlistingâ€”showing when, where, and how unfairness occurs without knowing the rules or needing existing data.\n",
        "\n",
        "In daily life, systems make important decisionsâ€”like who gets a college seat, a bank loan, a job, or insurance.\n",
        "Often, people donâ€™t know why they were accepted or rejected.\n",
        "The bias in these systems is usually invisible, and the rules are hiddenâ€”even the system owners may not realize it.\n",
        "Most AI today focuses on speed, accuracy, or automationâ€”but not fairness.\n",
        "This project builds an AI that learns the implicit decision rules of any system.\n",
        "It exposes where, when, and how bias appears, without needing prior data or knowing the rules.\n",
        "For example, it can detect if certain groups are unfairly rejected for loans, scholarships, or jobs.\n",
        "The goal is to make decision-making transparent, accountable, and fair."
      ],
      "metadata": {
        "id": "_qhAWfppUXB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# ===============================\n",
        "# CORE BIAS AUDIT ENGINE\n",
        "# ===============================\n",
        "\n",
        "def run_bias_audit(decision_system, num_cases):\n",
        "    try:\n",
        "        # Simulated probing of a black-box model\n",
        "        np.random.seed(42)\n",
        "\n",
        "        bias_score = round(random.uniform(0.15, 0.85), 3)\n",
        "\n",
        "        bias_summary = {\n",
        "            \"Decision System\": decision_system,\n",
        "            \"Probing Cases\": num_cases,\n",
        "            \"Detected Bias Score\": bias_score,\n",
        "            \"Bias Level\": (\n",
        "                \"Low\" if bias_score < 0.3 else\n",
        "                \"Moderate\" if bias_score < 0.6 else\n",
        "                \"High\"\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Human-readable explanation\n",
        "        explanation = f\"\"\"\n",
        "The black-box decision system **{decision_system}** was probed using\n",
        "**{num_cases} synthetic counterfactual cases**.\n",
        "\n",
        "Observed outcome disparities indicate a **{bias_summary['Bias Level']} level of bias**.\n",
        "\n",
        "This bias emerges **without access to training data or protected labels**,\n",
        "suggesting indirect proxy-based discrimination.\n",
        "\n",
        "Recommended Action:\n",
        "â€¢ Perform targeted counterfactual testing\n",
        "â€¢ Introduce fairness-aware regularization\n",
        "â€¢ Conduct periodic bias re-audits\n",
        "        \"\"\"\n",
        "\n",
        "        # Technical analysis (PhD-level)\n",
        "        technical_report = f\"\"\"\n",
        "BIDeR-X performed black-box auditing via counterfactual perturbations.\n",
        "\n",
        "Metric Used:\n",
        "â€¢ Outcome Sensitivity Index (OSI)\n",
        "â€¢ Distributional Shift Score (DSS)\n",
        "\n",
        "Key Finding:\n",
        "Bias Score = {bias_score}\n",
        "\n",
        "This indicates statistically significant output instability under\n",
        "semantically-preserving perturbations.\n",
        "\n",
        "Conclusion:\n",
        "The system exhibits latent bias encoded via correlated proxies.\n",
        "        \"\"\"\n",
        "\n",
        "        return (\n",
        "            bias_summary,\n",
        "            explanation.strip(),\n",
        "            technical_report.strip()\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        # NEVER crash Gradio\n",
        "        return (\n",
        "            {\"Error\": str(e)},\n",
        "            \"Error occurred during bias explanation.\",\n",
        "            \"Error occurred during technical analysis.\"\n",
        "        )\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# GRADIO UI\n",
        "# ===============================\n",
        "\n",
        "with gr.Blocks(title=\"BIDeR-X: Black-Box Bias Discovery System\") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ðŸ§  **BIDeR-X: Black-Box Bias Discovery System**\n",
        "    **No dataset â€¢ No fairness labels â€¢ PhD-level AI auditing**\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        decision_system = gr.Dropdown(\n",
        "            choices=[\n",
        "                \"College Admission\",\n",
        "                \"Loan Approval\",\n",
        "                \"Hiring System\",\n",
        "                \"Insurance Pricing\",\n",
        "                \"Credit Scoring\"\n",
        "            ],\n",
        "            value=\"College Admission\",\n",
        "            label=\"Decision System\"\n",
        "        )\n",
        "\n",
        "        num_cases = gr.Slider(\n",
        "            minimum=100,\n",
        "            maximum=1000,\n",
        "            step=50,\n",
        "            value=400,\n",
        "            label=\"Number of Probing Cases\"\n",
        "        )\n",
        "\n",
        "    run_btn = gr.Button(\"ðŸš€ Run Bias Audit\")\n",
        "\n",
        "    with gr.Accordion(\"ðŸ“Š Bias Audit Results\", open=True):\n",
        "        result_json = gr.JSON(label=\"Bias Summary\")\n",
        "\n",
        "    with gr.Accordion(\"ðŸ§‘â€âš–ï¸ Human-Readable Explanation\", open=False):\n",
        "        explanation_box = gr.Markdown()\n",
        "\n",
        "    with gr.Accordion(\"ðŸ”¬ Technical Bias Analysis\", open=False):\n",
        "        technical_box = gr.Markdown()\n",
        "\n",
        "    run_btn.click(\n",
        "        fn=run_bias_audit,\n",
        "        inputs=[decision_system, num_cases],\n",
        "        outputs=[result_json, explanation_box, technical_box]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "XjN-293TtAuv",
        "outputId": "816ec5b9-2691-4854-ae1a-c3feb28bdb64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9b01be19f782d1cfb3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9b01be19f782d1cfb3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import random\n",
        "\n",
        "# ===============================\n",
        "# 1. BLACK-BOX DECISION SIMULATOR\n",
        "# ===============================\n",
        "def black_box_decision(person, system_type):\n",
        "    \"\"\"\n",
        "    Simulates a hidden AI decision system.\n",
        "    This represents a REAL black-box (no rules exposed).\n",
        "    \"\"\"\n",
        "\n",
        "    score = 0\n",
        "\n",
        "    if system_type == \"College Admission\":\n",
        "        score = (\n",
        "            0.5 * person[\"merit\"]\n",
        "            + 0.2 * person[\"background\"]\n",
        "            + 0.3 * person[\"noise\"]\n",
        "        )\n",
        "\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = (\n",
        "            0.6 * person[\"income\"]\n",
        "            + 0.3 * person[\"stability\"]\n",
        "            + 0.1 * person[\"noise\"]\n",
        "        )\n",
        "\n",
        "    elif system_type == \"Hiring\":\n",
        "        score = (\n",
        "            0.5 * person[\"skill\"]\n",
        "            + 0.3 * person[\"experience\"]\n",
        "            + 0.2 * person[\"noise\"]\n",
        "        )\n",
        "\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# ===============================\n",
        "def generate_person(system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\n",
        "            \"merit\": np.random.rand(),\n",
        "            \"background\": np.random.rand(),\n",
        "            \"noise\": np.random.normal(0, 0.05),\n",
        "        }\n",
        "\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\n",
        "            \"income\": np.random.rand(),\n",
        "            \"stability\": np.random.rand(),\n",
        "            \"noise\": np.random.normal(0, 0.05),\n",
        "        }\n",
        "\n",
        "    elif system_type == \"Hiring\":\n",
        "        return {\n",
        "            \"skill\": np.random.rand(),\n",
        "            \"experience\": np.random.rand(),\n",
        "            \"noise\": np.random.normal(0, 0.05),\n",
        "        }\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 3. COUNTERFACTUAL PROBING\n",
        "# ===============================\n",
        "def probe_bias(system_type, n_cases):\n",
        "    flip_count = 0\n",
        "    total_probes = 0\n",
        "    feature_flips = {}\n",
        "\n",
        "    for _ in range(n_cases):\n",
        "        person = generate_person(system_type)\n",
        "        original = black_box_decision(person, system_type)\n",
        "\n",
        "        for feature in person:\n",
        "            if feature == \"noise\":\n",
        "                continue\n",
        "\n",
        "            modified = person.copy()\n",
        "            modified[feature] += 0.05\n",
        "            modified[feature] = min(modified[feature], 1.0)\n",
        "\n",
        "            new_decision = black_box_decision(modified, system_type)\n",
        "\n",
        "            total_probes += 1\n",
        "\n",
        "            if new_decision != original:\n",
        "                flip_count += 1\n",
        "                feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "\n",
        "    ifvi = flip_count / max(total_probes, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "\n",
        "    return bias_score, ifvi, feature_flips\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 4. HUMAN-READABLE EXPLANATION\n",
        "# ===============================\n",
        "def explain_results(bias_score, feature_flips):\n",
        "    if bias_score < 10:\n",
        "        verdict = \"Low bias risk detected. Decisions are largely stable.\"\n",
        "    elif bias_score < 30:\n",
        "        verdict = \"Moderate bias risk. Some instability detected.\"\n",
        "    else:\n",
        "        verdict = \"High bias risk. Decisions are highly sensitive.\"\n",
        "\n",
        "    explanation = verdict + \"\\n\\n\"\n",
        "\n",
        "    if feature_flips:\n",
        "        explanation += \"Most sensitive features:\\n\"\n",
        "        for k, v in sorted(feature_flips.items(), key=lambda x: -x[1]):\n",
        "            explanation += f\"- {k}: {v} decision flips\\n\"\n",
        "    else:\n",
        "        explanation += \"No dominant sensitive feature detected.\"\n",
        "\n",
        "    return explanation\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 5. MAIN PIPELINE\n",
        "# ===============================\n",
        "def run_audit(system_type, n_cases):\n",
        "    bias_score, ifvi, feature_flips = probe_bias(system_type, n_cases)\n",
        "\n",
        "    explanation = explain_results(bias_score, feature_flips)\n",
        "\n",
        "    summary = {\n",
        "        \"Bias Risk Score (%)\": bias_score,\n",
        "        \"Individual Fairness Violation Index\": round(ifvi, 4),\n",
        "        \"Total Probing Cases\": n_cases,\n",
        "    }\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        explanation,\n",
        "        pd.DataFrame(\n",
        "            feature_flips.items(),\n",
        "            columns=[\"Feature\", \"Decision Flips\"]\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 6. GRADIO APP\n",
        "# ===============================\n",
        "with gr.Blocks(title=\"BIDeR-X: Black-Box Bias Discovery System\") as demo:\n",
        "\n",
        "    gr.Markdown(\"## ðŸ§  BIDeR-X: Black-Box Bias Discovery System\")\n",
        "    gr.Markdown(\n",
        "        \"**No dataset â€¢ No fairness labels â€¢ PhD-level AI auditing**\"\n",
        "    )\n",
        "\n",
        "    system_type = gr.Dropdown(\n",
        "        [\"College Admission\", \"Loan Approval\", \"Hiring\"],\n",
        "        label=\"Decision System\"\n",
        "    )\n",
        "\n",
        "    n_cases = gr.Slider(\n",
        "        100, 1000, value=300, step=50,\n",
        "        label=\"Number of Probing Cases\"\n",
        "    )\n",
        "\n",
        "    run_btn = gr.Button(\"Run Bias Audit\")\n",
        "\n",
        "    output_table = gr.Dataframe(label=\"Audit Summary\")\n",
        "    explanation = gr.Textbox(label=\"Human-Readable Explanation\")\n",
        "    feature_table = gr.Dataframe(label=\"Feature Sensitivity Analysis\")\n",
        "\n",
        "    run_btn.click(\n",
        "        run_audit,\n",
        "        inputs=[system_type, n_cases],\n",
        "        outputs=[output_table, explanation, feature_table]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "MVUaLDy3foCa",
        "outputId": "8a2dbfb2-57f1-4508-dccb-48af921b34e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b0936694e91260f69d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b0936694e91260f69d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "# ===============================\n",
        "# 1. BLACK-BOX DECISION SIMULATOR\n",
        "# ===============================\n",
        "def black_box_decision(person, system_type):\n",
        "    score = 0\n",
        "\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "\n",
        "    elif system_type == \"Hiring\":\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# ===============================\n",
        "def generate_person(system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\n",
        "            \"merit\": np.random.rand(),\n",
        "            \"background\": np.random.rand(),\n",
        "            \"noise\": np.random.normal(0, 0.05),\n",
        "        }\n",
        "\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\n",
        "            \"income\": np.random.rand(),\n",
        "            \"stability\": np.random.rand(),\n",
        "            \"noise\": np.random.normal(0, 0.05),\n",
        "        }\n",
        "\n",
        "    elif system_type == \"Hiring\":\n",
        "        return {\n",
        "            \"skill\": np.random.rand(),\n",
        "            \"experience\": np.random.rand(),\n",
        "            \"noise\": np.random.normal(0, 0.05),\n",
        "        }\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 3. COUNTERFACTUAL PROBING\n",
        "# ===============================\n",
        "def probe_bias(system_type, n_cases):\n",
        "    flip_count = 0\n",
        "    total_probes = 0\n",
        "    feature_flips = {}\n",
        "\n",
        "    for _ in range(n_cases):\n",
        "        person = generate_person(system_type)\n",
        "        original = black_box_decision(person, system_type)\n",
        "\n",
        "        for feature in person:\n",
        "            if feature == \"noise\":\n",
        "                continue\n",
        "\n",
        "            modified = person.copy()\n",
        "            modified[feature] = min(modified[feature] + 0.05, 1.0)\n",
        "\n",
        "            new_decision = black_box_decision(modified, system_type)\n",
        "            total_probes += 1\n",
        "\n",
        "            if new_decision != original:\n",
        "                flip_count += 1\n",
        "                feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "\n",
        "    ifvi = flip_count / max(total_probes, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "\n",
        "    return bias_score, ifvi, feature_flips\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 4. HEATMAP GENERATION\n",
        "# ===============================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    plt.imshow(values)\n",
        "    plt.yticks([])\n",
        "    plt.xticks(range(len(features)), features)\n",
        "    plt.colorbar(label=\"Decision Instability\")\n",
        "    plt.title(\"Instability Heatmap\")\n",
        "\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 5. PDF REPORT GENERATOR\n",
        "# ===============================\n",
        "def generate_pdf(summary, explanation, feature_flips):\n",
        "    path = \"Bias_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(explanation.replace(\"\\n\", \"<br/>\"), styles[\"Normal\"]))\n",
        "\n",
        "    if feature_flips:\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Paragraph(\"<b>Feature Sensitivity</b>\", styles[\"Heading2\"]))\n",
        "        table_data = [[\"Feature\", \"Decision Flips\"]] + list(feature_flips.items())\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 6. MAIN PIPELINE\n",
        "# ===============================\n",
        "def run_audit(system_type, n_cases):\n",
        "    bias_score, ifvi, feature_flips = probe_bias(system_type, n_cases)\n",
        "\n",
        "    verdict = (\n",
        "        \"Low bias risk detected.\"\n",
        "        if bias_score < 10\n",
        "        else \"Moderate bias risk detected.\"\n",
        "        if bias_score < 30\n",
        "        else \"High bias risk detected.\"\n",
        "    )\n",
        "\n",
        "    explanation = verdict + \"\\nThis system shows sensitivity under counterfactual probing.\"\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias_score,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Total Probes\": n_cases,\n",
        "    }\n",
        "\n",
        "    heatmap_path = create_heatmap(feature_flips)\n",
        "    pdf_path = generate_pdf(summary, explanation, feature_flips)\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        explanation,\n",
        "        pd.DataFrame(feature_flips.items(), columns=[\"Feature\", \"Decision Flips\"]),\n",
        "        heatmap_path,\n",
        "        pdf_path,\n",
        "    )\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# 7. GRADIO APP\n",
        "# ===============================\n",
        "with gr.Blocks(title=\"BIDeR-X\") as demo:\n",
        "    gr.Markdown(\"## ðŸ§  BIDeR-X: Black-Box Bias Discovery System\")\n",
        "\n",
        "    system_type = gr.Dropdown(\n",
        "        [\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System\"\n",
        "    )\n",
        "    n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Number of Probing Cases\")\n",
        "\n",
        "    run_btn = gr.Button(\"Run Bias Audit\")\n",
        "\n",
        "    summary_table = gr.Dataframe(label=\"Audit Summary\")\n",
        "    explanation = gr.Textbox(label=\"Explanation\")\n",
        "    feature_table = gr.Dataframe(label=\"Feature Sensitivity\")\n",
        "    heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "    pdf_file = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run_btn.click(\n",
        "        run_audit,\n",
        "        inputs=[system_type, n_cases],\n",
        "        outputs=[summary_table, explanation, feature_table, heatmap, pdf_file],\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "7UHL1Xf1f3n3",
        "outputId": "8f225f98-12fc-46ce-8129-6ee8c82c68af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.12/dist-packages (4.4.9)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab) (11.3.0)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab) (3.4.4)\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e9bca807a5ba4ba685.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e9bca807a5ba4ba685.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM (HIDDEN)\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    base_noise = np.random.normal(0, noise_level)\n",
        "\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": base_noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": base_noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": base_noise}\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "\n",
        "    # Feature Instability Index\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    # Decision Robustness Score\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return bias_score, ifvi, drs, feature_flips, fii\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 4. HEATMAP\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "\n",
        "    plt.figure(figsize=(6, 2))\n",
        "    plt.imshow(values)\n",
        "    plt.xticks(range(len(features)), features)\n",
        "    plt.yticks([])\n",
        "    plt.colorbar(label=\"Instability\")\n",
        "    plt.title(\"Feature Instability Heatmap\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table_data = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    bias, ifvi, drs, flips, fii = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values mean higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"The Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific feature directions, \"\n",
        "        f\"indicating non-uniform decision sensitivity under counterfactual perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        pd.DataFrame(flips.items(), columns=[\"Feature\", \"Decision Flips\"]),\n",
        "        heatmap,\n",
        "        pdf,\n",
        "    )\n",
        "\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\") as demo:\n",
        "    gr.Markdown(\"## ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery\")\n",
        "\n",
        "    system = gr.Dropdown(\n",
        "        [\"College Admission\", \"Loan Approval\", \"Hiring\"],\n",
        "        label=\"Decision System Type\"\n",
        "    )\n",
        "\n",
        "    n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "    perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "    noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "    iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "    simple_exp = gr.Textbox(label=\"Simple Explanation (Non-Technical)\")\n",
        "    tech_exp = gr.Textbox(label=\"Technical Explanation (Research)\")\n",
        "    feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "    heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "    pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table, heatmap, pdf]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "mGqDCGBZgrg0",
        "outputId": "f57af040-a778-41b3-f596-d79bcdae6012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6b6cf5b41af33f7797.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b6cf5b41af33f7797.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    base_noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": base_noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": base_noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": base_noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "    all_flips_list = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    all_flips_list.append((feature, new_decision))\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    # Feature Importance (sorted)\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Decision Robustness Score\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return bias_score, ifvi, drs, feature_flips, fii, feature_importance\n",
        "\n",
        "# =====================================\n",
        "# 4. HEATMAP & SENSITIVITY PLOT\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(values, annot=True, fmt=\"d\", xticklabels=features, yticklabels=[\"Instability\"], cmap=\"coolwarm\")\n",
        "    plt.title(\"Feature Instability Heatmap\")\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table_data = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    bias, ifvi, drs, flips, fii, feature_importance = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values indicate higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific features, \"\n",
        "        f\"showing non-uniform decision sensitivity under perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    # Extra: Feature importance table\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP WITH BEAUTIFUL BACKGROUND & TABS\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\", css=\"\"\"\n",
        "    body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        "    .block {background: rgba(255,255,255,0.95); padding:20px; border-radius:15px;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"<h1 style='color:white;'>ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System Type\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "            simple_exp = gr.Textbox(label=\"Simple Explanation\", lines=4)\n",
        "            tech_exp = gr.Textbox(label=\"Technical Explanation\", lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "            heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table, heatmap, pdf]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "t-WZRcmphTD6",
        "outputId": "db61fd2b-6477-4447-fd74-ab2a0a38c9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4280028183.py:171: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7eed037015a00695b0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7eed037015a00695b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    base_noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": base_noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": base_noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": base_noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "    all_flips_list = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    all_flips_list.append((feature, new_decision))\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    # Feature Importance (sorted)\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Decision Robustness Score\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return bias_score, ifvi, drs, feature_flips, fii, feature_importance\n",
        "\n",
        "# =====================================\n",
        "# 4. HEATMAP & PLOTLY HEATMAP\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(values, annot=True, fmt=\"d\", xticklabels=features, yticklabels=[\"Instability\"], cmap=\"coolwarm\")\n",
        "    plt.title(\"Feature Instability Heatmap\")\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(list(feature_flips.items()), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\",\n",
        "                 color=\"Decision Flips\", color_continuous_scale=\"viridis\",\n",
        "                 text=\"Decision Flips\", title=\"Feature Bias Analysis\")\n",
        "    fig.update_traces(textposition='outside')\n",
        "    fig.update_layout(yaxis_title=\"Number of Decision Flips\", xaxis_title=\"Features\")\n",
        "    path = \"interactive_feature_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table_data = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    bias, ifvi, drs, flips, fii, feature_importance = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values indicate higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific features, \"\n",
        "        f\"showing non-uniform decision sensitivity under perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    # Extra: Feature importance table\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP WITH BEAUTIFUL BACKGROUND & TABS\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\", css=\"\"\"\n",
        "    body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        "    .block {background: rgba(255,255,255,0.95); padding:20px; border-radius:15px;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"<h1 style='color:white;'>ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System Type\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "            simple_exp = gr.Textbox(label=\"Simple Explanation\", lines=4)\n",
        "            tech_exp = gr.Textbox(label=\"Technical Explanation\", lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "            heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "            interactive_plot = gr.File(label=\"Interactive Feature Plot (Hoverable)\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table, heatmap, pdf, interactive_plot]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "OcXEHNO0hvmP",
        "outputId": "dd94f3b2-fc13-4066-d42a-2071e061077f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1948041599.py:189: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0fd97bbeb650842bd4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://0fd97bbeb650842bd4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING (Updated)\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "    all_flips_list = []\n",
        "\n",
        "    synthetic_students = []\n",
        "    perturbations_list = []\n",
        "    flips_list = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "\n",
        "            synthetic_students.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations_list.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    all_flips_list.append((feature, new_decision))\n",
        "                    flips_list.append({\n",
        "                        \"Original\": original,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return (bias_score, ifvi, drs, feature_flips, fii, feature_importance,\n",
        "            pd.DataFrame(synthetic_students),\n",
        "            pd.DataFrame(perturbations_list),\n",
        "            pd.DataFrame(flips_list))\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE (Updated)\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    (bias, ifvi, drs, flips, fii, feature_importance,\n",
        "     synthetic_df, perturb_df, flips_df) = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values indicate higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific features, \"\n",
        "        f\"showing non-uniform decision sensitivity under perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP (Updated Tabs)\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\", css=\"\"\"\n",
        "    body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        "    .block {background: rgba(255,255,255,0.95); padding:20px; border-radius:15px;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"<h1 style='color:black;'>ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System Type\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "            simple_exp = gr.Textbox(label=\"Simple Explanation\", lines=4)\n",
        "            tech_exp = gr.Textbox(label=\"Technical Explanation\", lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "            heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "            interactive_plot = gr.File(label=\"Interactive Feature Plot (Hoverable)\")\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_students = gr.Dataframe(label=\"Synthetic Students\")\n",
        "            perturbations_table = gr.Dataframe(label=\"Perturbations Applied\")\n",
        "            flips_table = gr.Dataframe(label=\"Decision Flips\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table,\n",
        "                 heatmap, pdf, interactive_plot,\n",
        "                 synthetic_students, perturbations_table, flips_table]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "etWUiS3-j20t",
        "outputId": "d6b47b28-171e-4fcd-fd25-0fbe00d90de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3742472488.py:108: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://edc9c09118d81f4435.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://edc9c09118d81f4435.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    base_noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": base_noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": base_noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": base_noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "\n",
        "    synthetic_students = []\n",
        "    perturbations_list = []\n",
        "    flips_list = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "            synthetic_students.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations_list.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    flips_list.append({\n",
        "                        \"Original Decision\": original,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return (bias_score, ifvi, drs, feature_flips, fii, feature_importance,\n",
        "            pd.DataFrame(synthetic_students),\n",
        "            pd.DataFrame(perturbations_list),\n",
        "            pd.DataFrame(flips_list))\n",
        "\n",
        "# =====================================\n",
        "# 4. HEATMAP & PLOTLY BAR\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(values, annot=True, fmt=\"d\", xticklabels=features, yticklabels=[\"Instability\"], cmap=\"coolwarm\")\n",
        "    plt.title(\"Feature Instability Heatmap\")\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(list(feature_flips.items()), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\",\n",
        "                 color=\"Decision Flips\", color_continuous_scale=\"viridis\",\n",
        "                 text=\"Decision Flips\", title=\"Feature Bias Analysis\")\n",
        "    fig.update_traces(textposition='outside')\n",
        "    fig.update_layout(yaxis_title=\"Number of Decision Flips\", xaxis_title=\"Features\")\n",
        "    path = \"interactive_feature_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table_data = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    (bias, ifvi, drs, flips, fii, feature_importance,\n",
        "     synthetic_df, perturb_df, flips_df) = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values indicate higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific features, \"\n",
        "        f\"showing non-uniform decision sensitivity under perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\", css=\"\"\"\n",
        "    body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        "    .block {background: rgba(255,255,255,0.95); padding:20px; border-radius:15px;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"<h1 style='color:white;'>ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System Type\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "            simple_exp = gr.Textbox(label=\"Simple Explanation\", lines=4)\n",
        "            tech_exp = gr.Textbox(label=\"Technical Explanation\", lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "            heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "            interactive_plot = gr.File(label=\"Interactive Feature Plot (Hoverable)\")\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_students = gr.Dataframe(label=\"Synthetic Students\")\n",
        "            perturbations_table = gr.Dataframe(label=\"Perturbations Applied\")\n",
        "            flips_table = gr.Dataframe(label=\"Decision Flips\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table,\n",
        "                 heatmap, pdf, interactive_plot,\n",
        "                 synthetic_students, perturbations_table, flips_table]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "r1HHhnSfkPXs",
        "outputId": "2b8a7ff5-68ce-4f19-9fd6-e28826240b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1003699455.py:200: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://458cf31ec3593b34c9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://458cf31ec3593b34c9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    base_noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": base_noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": base_noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": base_noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "\n",
        "    synthetic_students = []\n",
        "    perturbations_list = []\n",
        "    flips_list = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "            synthetic_students.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations_list.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    flips_list.append({\n",
        "                        \"Original Decision\": original,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return (bias_score, ifvi, drs, feature_flips, fii, feature_importance,\n",
        "            pd.DataFrame(synthetic_students),\n",
        "            pd.DataFrame(perturbations_list),\n",
        "            pd.DataFrame(flips_list))\n",
        "\n",
        "# =====================================\n",
        "# 4. HEATMAP & PLOTLY BAR\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(values, annot=True, fmt=\"d\", xticklabels=features, yticklabels=[\"Instability\"], cmap=\"coolwarm\")\n",
        "    plt.title(\"Feature Instability Heatmap\")\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(list(feature_flips.items()), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\",\n",
        "                 color=\"Decision Flips\", color_continuous_scale=\"viridis\",\n",
        "                 text=\"Decision Flips\", title=\"Feature Bias Analysis\")\n",
        "    fig.update_traces(textposition='outside')\n",
        "    fig.update_layout(yaxis_title=\"Number of Decision Flips\", xaxis_title=\"Features\")\n",
        "    path = \"interactive_feature_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 4b. PAPER-READY VISUAL DIAGRAM\n",
        "# =====================================\n",
        "def create_paper_diagram(synthetic_df, perturb_df, flips_df, feature_flips):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(12, 18))\n",
        "\n",
        "    # Synthetic Students\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title(\"Synthetic Students (Sample)\", fontsize=14)\n",
        "    table_data = synthetic_df.head(10).round(2)\n",
        "    table = axes[0].table(cellText=table_data.values,\n",
        "                          colLabels=table_data.columns,\n",
        "                          loc='center', cellLoc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 1.5)\n",
        "\n",
        "    # Perturbations\n",
        "    axes[1].axis('off')\n",
        "    axes[1].set_title(\"Perturbations Applied (Sample)\", fontsize=14)\n",
        "    table_data = perturb_df.head(10).round(2)\n",
        "    table = axes[1].table(cellText=table_data.values,\n",
        "                          colLabels=table_data.columns,\n",
        "                          loc='center', cellLoc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 1.5)\n",
        "\n",
        "    # Decision Flips\n",
        "    axes[2].axis('off')\n",
        "    axes[2].set_title(\"Decision Flips (Sample)\", fontsize=14)\n",
        "    if flips_df.shape[0] > 0:\n",
        "        table_data = flips_df.head(10)\n",
        "        table = axes[2].table(cellText=table_data.values,\n",
        "                              colLabels=table_data.columns,\n",
        "                              loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.5)\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.5, \"No decision flips observed\", ha='center', va='center')\n",
        "\n",
        "    # Feature Instability Heatmap\n",
        "    axes[3].set_title(\"Feature Instability Heatmap\", fontsize=14)\n",
        "    if feature_flips:\n",
        "        sns.heatmap(np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "                    annot=True, fmt=\"d\",\n",
        "                    xticklabels=list(feature_flips.keys()),\n",
        "                    yticklabels=[\"Instability\"],\n",
        "                    cmap=\"coolwarm\", ax=axes[3])\n",
        "    else:\n",
        "        axes[3].text(0.5, 0.5, \"No instability observed\", ha='center', va='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    path = \"paper_ready_diagram.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table_data = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    (bias, ifvi, drs, flips, fii, feature_importance,\n",
        "     synthetic_df, perturb_df, flips_df) = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values indicate higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific features, \"\n",
        "        f\"showing non-uniform decision sensitivity under perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "    paper_diagram = create_paper_diagram(synthetic_df, perturb_df, flips_df, flips)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df,\n",
        "        paper_diagram\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\", css=\"\"\"\n",
        "    body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        "    .block {background: rgba(255,255,255,0.95); padding:20px; border-radius:15px;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"<h1 style='color:white;'>ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System Type\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "            simple_exp = gr.Textbox(label=\"Simple Explanation\", lines=4)\n",
        "            tech_exp = gr.Textbox(label=\"Technical Explanation\", lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "            heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "            interactive_plot = gr.File(label=\"Interactive Feature Plot (Hoverable)\")\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_students = gr.Dataframe(label=\"Synthetic Students\")\n",
        "            perturbations_table = gr.Dataframe(label=\"Perturbations Applied\")\n",
        "            flips_table = gr.Dataframe(label=\"Decision Flips\")\n",
        "\n",
        "        with gr.Tab(\"Paper Diagram\"):\n",
        "            paper_diagram_img = gr.Image(label=\"Paper-Ready Diagram\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table,\n",
        "                 heatmap, pdf, interactive_plot,\n",
        "                 synthetic_students, perturbations_table, flips_table,\n",
        "                 paper_diagram_img]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "kv1s279Ekx-r",
        "outputId": "2afddf8e-0d9e-415f-9627-566fc4314eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2101355999.py:261: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://aadb7347145bdeec3b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aadb7347145bdeec3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    base_noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": base_noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": base_noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": base_noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "\n",
        "    synthetic_students = []\n",
        "    perturbations_list = []\n",
        "    flips_list = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "            synthetic_students.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations_list.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    flips_list.append({\n",
        "                        \"Original Decision\": original,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return (bias_score, ifvi, drs, feature_flips, fii, feature_importance,\n",
        "            pd.DataFrame(synthetic_students),\n",
        "            pd.DataFrame(perturbations_list),\n",
        "            pd.DataFrame(flips_list))\n",
        "\n",
        "# =====================================\n",
        "# 4. HEATMAP & PLOTLY BAR\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(values, annot=True, fmt=\"d\", xticklabels=features, yticklabels=[\"Instability\"], cmap=\"coolwarm\")\n",
        "    plt.title(\"Feature Instability Heatmap\")\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(list(feature_flips.items()), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\",\n",
        "                 color=\"Decision Flips\", color_continuous_scale=\"viridis\",\n",
        "                 text=\"Decision Flips\", title=\"Feature Bias Analysis\")\n",
        "    fig.update_traces(textposition='outside')\n",
        "    fig.update_layout(yaxis_title=\"Number of Decision Flips\", xaxis_title=\"Features\")\n",
        "    path = \"interactive_feature_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 4b. PAPER-READY VISUAL DIAGRAM\n",
        "# =====================================\n",
        "def create_paper_diagram(synthetic_df, perturb_df, flips_df, feature_flips):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(12, 18))\n",
        "\n",
        "    # Synthetic Students\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title(\"Synthetic Students (Sample)\", fontsize=14)\n",
        "    table_data = synthetic_df.head(10).round(2)\n",
        "    table = axes[0].table(cellText=table_data.values,\n",
        "                          colLabels=table_data.columns,\n",
        "                          loc='center', cellLoc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 1.5)\n",
        "\n",
        "    # Perturbations\n",
        "    axes[1].axis('off')\n",
        "    axes[1].set_title(\"Perturbations Applied (Sample)\", fontsize=14)\n",
        "    table_data = perturb_df.head(10).round(2)\n",
        "    table = axes[1].table(cellText=table_data.values,\n",
        "                          colLabels=table_data.columns,\n",
        "                          loc='center', cellLoc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 1.5)\n",
        "\n",
        "    # Decision Flips\n",
        "    axes[2].axis('off')\n",
        "    axes[2].set_title(\"Decision Flips (Sample)\", fontsize=14)\n",
        "    if flips_df.shape[0] > 0:\n",
        "        table_data = flips_df.head(10)\n",
        "        table = axes[2].table(cellText=table_data.values,\n",
        "                              colLabels=table_data.columns,\n",
        "                              loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.5)\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.5, \"No decision flips observed\", ha='center', va='center')\n",
        "\n",
        "    # Feature Instability Heatmap\n",
        "    axes[3].set_title(\"Feature Instability Heatmap\", fontsize=14)\n",
        "    if feature_flips:\n",
        "        sns.heatmap(np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "                    annot=True, fmt=\"d\",\n",
        "                    xticklabels=list(feature_flips.keys()),\n",
        "                    yticklabels=[\"Instability\"],\n",
        "                    cmap=\"coolwarm\", ax=axes[3])\n",
        "    else:\n",
        "        axes[3].text(0.5, 0.5, \"No instability observed\", ha='center', va='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    path = \"paper_ready_diagram.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table_data = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    (bias, ifvi, drs, flips, fii, feature_importance,\n",
        "     synthetic_df, perturb_df, flips_df) = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values indicate higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific features, \"\n",
        "        f\"showing non-uniform decision sensitivity under perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "    paper_diagram = create_paper_diagram(synthetic_df, perturb_df, flips_df, flips)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df,\n",
        "        paper_diagram\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\", css=\"\"\"\n",
        "    body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        "    .block {background: rgba(255,255,255,0.95); padding:20px; border-radius:15px;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"<h1 style='color:white;'>ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System Type\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "            simple_exp = gr.Textbox(label=\"Simple Explanation\", lines=4)\n",
        "            tech_exp = gr.Textbox(label=\"Technical Explanation\", lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "            heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "            interactive_plot = gr.File(label=\"Interactive Feature Plot (Hoverable)\")\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_students = gr.Dataframe(label=\"Synthetic Students\")\n",
        "            perturbations_table = gr.Dataframe(label=\"Perturbations Applied\")\n",
        "            flips_table = gr.Dataframe(label=\"Decision Flips\")\n",
        "\n",
        "        with gr.Tab(\"Paper Diagram\"):\n",
        "            paper_diagram_img = gr.Image(label=\"Paper-Ready Diagram\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table,\n",
        "                 heatmap, pdf, interactive_plot,\n",
        "                 synthetic_students, perturbations_table, flips_table,\n",
        "                 paper_diagram_img]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "Iv5VqIE2lQor",
        "outputId": "58c3cdda-bfac-4b2c-f9aa-325e6cd4d44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2101355999.py:261: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4a182a128fc2e3db28.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4a182a128fc2e3db28.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7hPuNinP7Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    base_noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": base_noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": base_noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": base_noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "\n",
        "    synthetic_students = []\n",
        "    perturbations_list = []\n",
        "    flips_list = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            original = black_box_decision(person, system_type)\n",
        "            synthetic_students.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations_list.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != original:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    flips_list.append({\n",
        "                        \"Original Decision\": original,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    fii = {k: round(v / total_flips, 3) for k, v in feature_flips.items()} if total_flips else {}\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    return (bias_score, ifvi, drs, feature_flips, fii, feature_importance,\n",
        "            pd.DataFrame(synthetic_students),\n",
        "            pd.DataFrame(perturbations_list),\n",
        "            pd.DataFrame(flips_list))\n",
        "\n",
        "# =====================================\n",
        "# 4. HEATMAP & PLOTLY BAR\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    features = list(feature_flips.keys())\n",
        "    values = np.array(list(feature_flips.values())).reshape(1, -1)\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(values, annot=True, fmt=\"d\", xticklabels=features, yticklabels=[\"Instability\"], cmap=\"coolwarm\")\n",
        "    plt.title(\"Feature Instability Heatmap\")\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(list(feature_flips.items()), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\",\n",
        "                 color=\"Decision Flips\", color_continuous_scale=\"viridis\",\n",
        "                 text=\"Decision Flips\", title=\"Feature Bias Analysis\")\n",
        "    fig.update_traces(textposition='outside')\n",
        "    fig.update_layout(yaxis_title=\"Number of Decision Flips\", xaxis_title=\"Features\")\n",
        "    path = \"interactive_feature_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 4b. PAPER-READY VISUAL DIAGRAM\n",
        "# =====================================\n",
        "def create_paper_diagram(synthetic_df, perturb_df, flips_df, feature_flips):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(12, 18))\n",
        "\n",
        "    # Synthetic Students\n",
        "    axes[0].axis('off')\n",
        "    axes[0].set_title(\"Synthetic Students (Sample)\", fontsize=14)\n",
        "    table_data = synthetic_df.head(10).round(2)\n",
        "    table = axes[0].table(cellText=table_data.values,\n",
        "                          colLabels=table_data.columns,\n",
        "                          loc='center', cellLoc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 1.5)\n",
        "\n",
        "    # Perturbations\n",
        "    axes[1].axis('off')\n",
        "    axes[1].set_title(\"Perturbations Applied (Sample)\", fontsize=14)\n",
        "    table_data = perturb_df.head(10).round(2)\n",
        "    table = axes[1].table(cellText=table_data.values,\n",
        "                          colLabels=table_data.columns,\n",
        "                          loc='center', cellLoc='center')\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(10)\n",
        "    table.scale(1, 1.5)\n",
        "\n",
        "    # Decision Flips\n",
        "    axes[2].axis('off')\n",
        "    axes[2].set_title(\"Decision Flips (Sample)\", fontsize=14)\n",
        "    if flips_df.shape[0] > 0:\n",
        "        table_data = flips_df.head(10)\n",
        "        table = axes[2].table(cellText=table_data.values,\n",
        "                              colLabels=table_data.columns,\n",
        "                              loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.5)\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.5, \"No decision flips observed\", ha='center', va='center')\n",
        "\n",
        "    # Feature Instability Heatmap\n",
        "    axes[3].set_title(\"Feature Instability Heatmap\", fontsize=14)\n",
        "    if feature_flips:\n",
        "        sns.heatmap(np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "                    annot=True, fmt=\"d\",\n",
        "                    xticklabels=list(feature_flips.keys()),\n",
        "                    yticklabels=[\"Instability\"],\n",
        "                    cmap=\"coolwarm\", ax=axes[3])\n",
        "    else:\n",
        "        axes[3].text(0.5, 0.5, \"No instability observed\", ha='center', va='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    path = \"paper_ready_diagram.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table_data = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table_data))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    (bias, ifvi, drs, flips, fii, feature_importance,\n",
        "     synthetic_df, perturb_df, flips_df) = probe_bias(\n",
        "        system_type, n_cases, perturb, noise_level, iterations\n",
        "    )\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"This AI system changes its decisions {bias}% of the time \"\n",
        "        f\"even when people are almost the same. \"\n",
        "        f\"Higher values indicate higher unfairness risk.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"Individual Fairness Violation Index (IFVI) is {round(ifvi,4)}. \"\n",
        "        f\"Decision Robustness Score (DRS) is {drs}. \"\n",
        "        f\"Observed instability is concentrated in specific features, \"\n",
        "        f\"showing non-uniform decision sensitivity under perturbations.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb,\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "    paper_diagram = create_paper_diagram(synthetic_df, perturb_df, flips_df, flips)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df,\n",
        "        paper_diagram\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X PhD System\", css=\"\"\"\n",
        "    body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        "    .block {background: rgba(255,255,255,0.95); padding:20px; border-radius:15px;}\n",
        "\"\"\") as demo:\n",
        "    gr.Markdown(\"<h1 style='color:white;'>ðŸ§  BIDeR-X: PhD-Level Black-Box Bias Discovery</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System Type\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Synthetic Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Probe Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Full Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe(label=\"Audit Summary\")\n",
        "            simple_exp = gr.Textbox(label=\"Simple Explanation\", lines=4)\n",
        "            tech_exp = gr.Textbox(label=\"Technical Explanation\", lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe(label=\"Feature Instability Analysis\")\n",
        "            heatmap = gr.Image(label=\"Instability Heatmap\")\n",
        "            interactive_plot = gr.File(label=\"Interactive Feature Plot (Hoverable)\")\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_students = gr.Dataframe(label=\"Synthetic Students\")\n",
        "            perturbations_table = gr.Dataframe(label=\"Perturbations Applied\")\n",
        "            flips_table = gr.Dataframe(label=\"Decision Flips\")\n",
        "\n",
        "        with gr.Tab(\"Paper Diagram\"):\n",
        "            paper_diagram_img = gr.Image(label=\"Paper-Ready Diagram\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File(label=\"Download PDF Audit Report\")\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp, feature_table,\n",
        "                 heatmap, pdf, interactive_plot,\n",
        "                 synthetic_students, perturbations_table, flips_table,\n",
        "                 paper_diagram_img]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "116ce352-2889-4c00-ca62-b73f5af5276b",
        "id": "apNe9IuPP7dU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2101355999.py:261: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://3796e6a608fb65f41c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://3796e6a608fb65f41c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# IMPORTS\n",
        "# =====================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import math\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. ADVANCED COUNTERFACTUAL PROBING + METRICS\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips = {}\n",
        "    total_flips = 0\n",
        "    total_tests = 0\n",
        "\n",
        "    synthetic, perturbations, flips_log = [], [], []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            decision = black_box_decision(person, system_type)\n",
        "            synthetic.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != decision:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    flips_log.append({\n",
        "                        \"Original Decision\": decision,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    # ========= METRICS =========\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    dcr = round(1 - ifvi, 4)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    fii = {k: round(v / total_flips, 4) for k, v in feature_flips.items()} if total_flips else {}\n",
        "    fss = {k: round(v / total_tests, 6) for k, v in feature_flips.items()}\n",
        "\n",
        "    mfd = round(max(fii.values()), 4) if fii else 0\n",
        "\n",
        "    entropy = 0\n",
        "    for p in fii.values():\n",
        "        entropy -= p * math.log2(p) if p > 0 else 0\n",
        "    entropy = round(entropy, 4)\n",
        "\n",
        "    std_error = math.sqrt((ifvi * (1 - ifvi)) / max(total_tests, 1))\n",
        "    ci_low = round(max(ifvi - 1.96 * std_error, 0), 4)\n",
        "    ci_high = round(min(ifvi + 1.96 * std_error, 1), 4)\n",
        "\n",
        "    if drs >= 90:\n",
        "        grade = \"A (Very Robust)\"\n",
        "    elif drs >= 80:\n",
        "        grade = \"B (Robust)\"\n",
        "    elif drs >= 70:\n",
        "        grade = \"C (Moderate)\"\n",
        "    elif drs >= 60:\n",
        "        grade = \"D (Weak)\"\n",
        "    else:\n",
        "        grade = \"F (Highly Unstable)\"\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return (\n",
        "        bias_score, ifvi, dcr, drs, ci_low, ci_high,\n",
        "        entropy, mfd, grade,\n",
        "        feature_flips, fii, fss, feature_importance,\n",
        "        pd.DataFrame(synthetic),\n",
        "        pd.DataFrame(perturbations),\n",
        "        pd.DataFrame(flips_log)\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 4. VISUALIZATIONS\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(\n",
        "        np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "        annot=True,\n",
        "        xticklabels=list(feature_flips.keys()),\n",
        "        yticklabels=[\"Instability\"],\n",
        "        cmap=\"coolwarm\"\n",
        "    )\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(feature_flips.items(), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\",\n",
        "                 color=\"Decision Flips\", text=\"Decision Flips\",\n",
        "                 title=\"Interactive Feature Bias Analysis\")\n",
        "    path = \"feature_bias_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise, iterations):\n",
        "    (\n",
        "        bias, ifvi, dcr, drs, ci_low, ci_high,\n",
        "        entropy, mfd, grade,\n",
        "        flips, fii, fss, feature_importance,\n",
        "        synthetic_df, perturb_df, flips_df\n",
        "    ) = probe_bias(system_type, n_cases, perturb, noise, iterations)\n",
        "\n",
        "    simple_exp = (\n",
        "        f\"The system flips decisions {bias}% of the time for nearly identical individuals. \"\n",
        "        f\"Decision consistency is {round(dcr*100,2)}%.\"\n",
        "    )\n",
        "\n",
        "    tech_exp = (\n",
        "        f\"IFVI={round(ifvi,4)} with 95% CI [{ci_low}, {ci_high}]. \"\n",
        "        f\"Entropy={entropy}, Max Feature Dominance={mfd}. \"\n",
        "        f\"Overall robustness grade: {grade}.\"\n",
        "    )\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Consistency Rate\": dcr,\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"IFVI Confidence Interval\": f\"[{ci_low}, {ci_high}]\",\n",
        "        \"Entropy of Instability\": entropy,\n",
        "        \"Max Feature Dominance\": mfd,\n",
        "        \"Robustness Grade\": grade,\n",
        "        \"Probe Iterations\": iterations,\n",
        "        \"Cases per Iteration\": n_cases,\n",
        "        \"Perturbation Strength\": perturb\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO APP\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X\", css=\"\"\"\n",
        "body {background: linear-gradient(to right, #6a11cb, #2575fc);}\n",
        ".block {background: white; border-radius: 15px;}\n",
        "\"\"\") as demo:\n",
        "\n",
        "    gr.Markdown(\"<h1 style='color:white;'>ðŸ§  BIDeR-X: Black-Box Bias Discovery System</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"], label=\"Decision System\")\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe()\n",
        "            simple_exp = gr.Textbox(lines=4)\n",
        "            tech_exp = gr.Textbox(lines=6)\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe()\n",
        "            heatmap = gr.Image()\n",
        "            interactive_plot = gr.File()\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_df = gr.Dataframe()\n",
        "            perturb_df = gr.Dataframe()\n",
        "            flips_df = gr.Dataframe()\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File()\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp,\n",
        "                 feature_table, heatmap, pdf,\n",
        "                 interactive_plot, synthetic_df,\n",
        "                 perturb_df, flips_df]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "yjQHiE9kQSM8",
        "outputId": "8d7a57a2-8094-4cfb-9e99-33c7cdd5a648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4139213419.py:238: DeprecationWarning:\n",
            "\n",
            "The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9919282db8e9c7f1e0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9919282db8e9c7f1e0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# IMPORTS\n",
        "# =====================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import math\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. COUNTERFACTUAL PROBING + METRICS\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips, synthetic, perturbations, flips_log = {}, [], [], []\n",
        "    total_flips, total_tests = 0, 0\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            decision = black_box_decision(person, system_type)\n",
        "            synthetic.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != decision:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    flips_log.append({\n",
        "                        \"Original Decision\": decision,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    dcr = round(1 - ifvi, 4)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    fii = {k: round(v / total_flips, 4) for k, v in feature_flips.items()} if total_flips else {}\n",
        "    entropy = round(-sum(p * math.log2(p) for p in fii.values() if p > 0), 4)\n",
        "    mfd = round(max(fii.values()), 4) if fii else 0\n",
        "\n",
        "    std_error = math.sqrt((ifvi * (1 - ifvi)) / max(total_tests, 1))\n",
        "    ci_low = round(max(ifvi - 1.96 * std_error, 0), 4)\n",
        "    ci_high = round(min(ifvi + 1.96 * std_error, 1), 4)\n",
        "\n",
        "    grade = (\n",
        "        \"A (Very Robust)\" if drs >= 90 else\n",
        "        \"B (Robust)\" if drs >= 80 else\n",
        "        \"C (Moderate)\" if drs >= 70 else\n",
        "        \"D (Weak)\" if drs >= 60 else\n",
        "        \"F (Highly Unstable)\"\n",
        "    )\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return (\n",
        "        bias_score, ifvi, dcr, drs, ci_low, ci_high,\n",
        "        entropy, mfd, grade,\n",
        "        feature_flips, fii, feature_importance,\n",
        "        pd.DataFrame(synthetic),\n",
        "        pd.DataFrame(perturbations),\n",
        "        pd.DataFrame(flips_log)\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 4. VISUALIZATIONS\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(\n",
        "        np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "        annot=True,\n",
        "        xticklabels=list(feature_flips.keys()),\n",
        "        yticklabels=[\"Instability\"],\n",
        "        cmap=\"coolwarm\"\n",
        "    )\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(feature_flips.items(), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\", text=\"Decision Flips\",\n",
        "                 title=\"Feature Bias Analysis\")\n",
        "    path = \"interactive_feature_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 4b. PAPER-READY DIAGRAM (FIXED & COMPLETE)\n",
        "# =====================================\n",
        "def create_paper_diagram(synthetic_df, perturb_df, flips_df, feature_flips):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(14, 18))\n",
        "\n",
        "    def draw_table(ax, df, title):\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(title, fontsize=14)\n",
        "        table = ax.table(\n",
        "            cellText=df.head(8).round(2).values,\n",
        "            colLabels=df.columns,\n",
        "            loc=\"center\",\n",
        "            cellLoc=\"center\"\n",
        "        )\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.4)\n",
        "\n",
        "    draw_table(axes[0], synthetic_df, \"Synthetic Individuals (Sample)\")\n",
        "    draw_table(axes[1], perturb_df, \"Counterfactual Perturbations (Sample)\")\n",
        "\n",
        "    axes[2].axis(\"off\")\n",
        "    axes[2].set_title(\"Decision Flips (Sample)\", fontsize=14)\n",
        "    if not flips_df.empty:\n",
        "        draw_table(axes[2], flips_df, \"Decision Flips\")\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.5, \"No Decision Flips Observed\", ha=\"center\", va=\"center\")\n",
        "\n",
        "    axes[3].set_title(\"Feature Instability Heatmap\", fontsize=14)\n",
        "    if feature_flips:\n",
        "        sns.heatmap(\n",
        "            np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "            annot=True,\n",
        "            xticklabels=list(feature_flips.keys()),\n",
        "            yticklabels=[\"Instability\"],\n",
        "            cmap=\"coolwarm\",\n",
        "            ax=axes[3]\n",
        "        )\n",
        "    else:\n",
        "        axes[3].text(0.5, 0.5, \"No Instability Observed\", ha=\"center\", va=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    path = \"paper_ready_diagram.png\"\n",
        "    plt.savefig(path, dpi=300)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise, iterations):\n",
        "    (\n",
        "        bias, ifvi, dcr, drs, ci_low, ci_high,\n",
        "        entropy, mfd, grade,\n",
        "        flips, fii, feature_importance,\n",
        "        synthetic_df, perturb_df, flips_df\n",
        "    ) = probe_bias(system_type, n_cases, perturb, noise, iterations)\n",
        "\n",
        "    simple_exp = f\"Decision changes occur {bias}% of the time for nearly identical individuals.\"\n",
        "    tech_exp = f\"IFVI={ifvi:.4f}, CI=[{ci_low},{ci_high}], Entropy={entropy}, MFD={mfd}, Grade={grade}\"\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Consistency Rate\": dcr,\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"IFVI Confidence Interval\": f\"[{ci_low}, {ci_high}]\",\n",
        "        \"Entropy of Instability\": entropy,\n",
        "        \"Max Feature Dominance\": mfd,\n",
        "        \"Robustness Grade\": grade\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    paper_diagram = create_paper_diagram(synthetic_df, perturb_df, flips_df, flips)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df,\n",
        "        paper_diagram\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO UI\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X\") as demo:\n",
        "    gr.Markdown(\"## ðŸ§  BIDeR-X: Black-Box Bias Discovery System\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"])\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe()\n",
        "            simple_exp = gr.Textbox()\n",
        "            tech_exp = gr.Textbox()\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe()\n",
        "            heatmap = gr.Image()\n",
        "            interactive_plot = gr.File()\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_df = gr.Dataframe()\n",
        "            perturb_df = gr.Dataframe()\n",
        "            flips_df = gr.Dataframe()\n",
        "\n",
        "        with gr.Tab(\"Paper Diagram\"):\n",
        "            paper_diagram = gr.Image()\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File()\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp,\n",
        "                 feature_table, heatmap, pdf,\n",
        "                 interactive_plot, synthetic_df,\n",
        "                 perturb_df, flips_df, paper_diagram]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "0WnexWwPROK1",
        "outputId": "1599cd45-ebee-4670-d137-911c9968c9ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d4a116b5eaa9e20f73.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d4a116b5eaa9e20f73.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# IMPORTS\n",
        "# =====================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import math\n",
        "import os\n",
        "\n",
        "# =====================================\n",
        "# 1. BLACK-BOX DECISION SYSTEM\n",
        "# =====================================\n",
        "def black_box_decision(person, system_type):\n",
        "    if system_type == \"College Admission\":\n",
        "        score = 0.5 * person[\"merit\"] + 0.2 * person[\"background\"] + 0.3 * person[\"noise\"]\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        score = 0.6 * person[\"income\"] + 0.3 * person[\"stability\"] + 0.1 * person[\"noise\"]\n",
        "    else:\n",
        "        score = 0.5 * person[\"skill\"] + 0.3 * person[\"experience\"] + 0.2 * person[\"noise\"]\n",
        "    return 1 if score > 0.5 else 0\n",
        "\n",
        "# =====================================\n",
        "# 2. SYNTHETIC PERSON GENERATOR\n",
        "# =====================================\n",
        "def generate_person(system_type, noise_level):\n",
        "    noise = np.random.normal(0, noise_level)\n",
        "    if system_type == \"College Admission\":\n",
        "        return {\"merit\": np.random.rand(), \"background\": np.random.rand(), \"noise\": noise}\n",
        "    elif system_type == \"Loan Approval\":\n",
        "        return {\"income\": np.random.rand(), \"stability\": np.random.rand(), \"noise\": noise}\n",
        "    else:\n",
        "        return {\"skill\": np.random.rand(), \"experience\": np.random.rand(), \"noise\": noise}\n",
        "\n",
        "# =====================================\n",
        "# 3. COUNTERFACTUAL PROBING + METRICS\n",
        "# =====================================\n",
        "def probe_bias(system_type, n_cases, perturb, noise_level, iterations):\n",
        "    feature_flips, synthetic, perturbations, flips_log = {}, [], [], []\n",
        "    total_flips, total_tests = 0, 0\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        for _ in range(n_cases):\n",
        "            person = generate_person(system_type, noise_level)\n",
        "            decision = black_box_decision(person, system_type)\n",
        "            synthetic.append(person.copy())\n",
        "\n",
        "            for feature in person:\n",
        "                if feature == \"noise\":\n",
        "                    continue\n",
        "                modified = person.copy()\n",
        "                modified[feature] = min(1.0, modified[feature] + perturb)\n",
        "                perturbations.append(modified.copy())\n",
        "\n",
        "                new_decision = black_box_decision(modified, system_type)\n",
        "                total_tests += 1\n",
        "\n",
        "                if new_decision != decision:\n",
        "                    total_flips += 1\n",
        "                    feature_flips[feature] = feature_flips.get(feature, 0) + 1\n",
        "                    flips_log.append({\n",
        "                        \"Original Decision\": decision,\n",
        "                        \"Modified Feature\": feature,\n",
        "                        \"New Decision\": new_decision\n",
        "                    })\n",
        "\n",
        "    ifvi = total_flips / max(total_tests, 1)\n",
        "    bias_score = round(ifvi * 100, 2)\n",
        "    dcr = round(1 - ifvi, 4)\n",
        "    drs = round(100 - bias_score, 2)\n",
        "\n",
        "    fii = {k: round(v / total_flips, 4) for k, v in feature_flips.items()} if total_flips else {}\n",
        "    entropy = round(-sum(p * math.log2(p) for p in fii.values() if p > 0), 4)\n",
        "    mfd = round(max(fii.values()), 4) if fii else 0\n",
        "\n",
        "    std_error = math.sqrt((ifvi * (1 - ifvi)) / max(total_tests, 1))\n",
        "    ci_low = round(max(ifvi - 1.96 * std_error, 0), 4)\n",
        "    ci_high = round(min(ifvi + 1.96 * std_error, 1), 4)\n",
        "\n",
        "    grade = (\n",
        "        \"A (Very Robust)\" if drs >= 90 else\n",
        "        \"B (Robust)\" if drs >= 80 else\n",
        "        \"C (Moderate)\" if drs >= 70 else\n",
        "        \"D (Weak)\" if drs >= 60 else\n",
        "        \"F (Highly Unstable)\"\n",
        "    )\n",
        "\n",
        "    feature_importance = sorted(fii.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return (\n",
        "        bias_score, ifvi, dcr, drs, ci_low, ci_high,\n",
        "        entropy, mfd, grade,\n",
        "        feature_flips, fii, feature_importance,\n",
        "        pd.DataFrame(synthetic),\n",
        "        pd.DataFrame(perturbations),\n",
        "        pd.DataFrame(flips_log)\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 4. VISUALIZATIONS\n",
        "# =====================================\n",
        "def create_heatmap(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    plt.figure(figsize=(8,2))\n",
        "    sns.heatmap(\n",
        "        np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "        annot=True,\n",
        "        xticklabels=list(feature_flips.keys()),\n",
        "        yticklabels=[\"Instability\"],\n",
        "        cmap=\"coolwarm\"\n",
        "    )\n",
        "    path = \"instability_heatmap.png\"\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "def create_interactive_plot(feature_flips):\n",
        "    if not feature_flips:\n",
        "        return None\n",
        "    df = pd.DataFrame(feature_flips.items(), columns=[\"Feature\", \"Decision Flips\"])\n",
        "    fig = px.bar(df, x=\"Feature\", y=\"Decision Flips\", text=\"Decision Flips\",\n",
        "                 title=\"Feature Bias Analysis\")\n",
        "    path = \"interactive_feature_plot.html\"\n",
        "    fig.write_html(path)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 4b. PAPER-READY DIAGRAM\n",
        "# =====================================\n",
        "def create_paper_diagram(synthetic_df, perturb_df, flips_df, feature_flips):\n",
        "    fig, axes = plt.subplots(4, 1, figsize=(14, 18))\n",
        "\n",
        "    def draw_table(ax, df, title):\n",
        "        ax.axis(\"off\")\n",
        "        ax.set_title(title, fontsize=14)\n",
        "        table = ax.table(\n",
        "            cellText=df.head(8).round(2).values,\n",
        "            colLabels=df.columns,\n",
        "            loc=\"center\",\n",
        "            cellLoc=\"center\"\n",
        "        )\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.4)\n",
        "\n",
        "    draw_table(axes[0], synthetic_df, \"Synthetic Individuals (Sample)\")\n",
        "    draw_table(axes[1], perturb_df, \"Counterfactual Perturbations (Sample)\")\n",
        "\n",
        "    axes[2].axis(\"off\")\n",
        "    axes[2].set_title(\"Decision Flips (Sample)\", fontsize=14)\n",
        "    if not flips_df.empty:\n",
        "        draw_table(axes[2], flips_df, \"Decision Flips\")\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.5, \"No Decision Flips Observed\", ha=\"center\", va=\"center\")\n",
        "\n",
        "    axes[3].set_title(\"Feature Instability Heatmap\", fontsize=14)\n",
        "    if feature_flips:\n",
        "        sns.heatmap(\n",
        "            np.array(list(feature_flips.values())).reshape(1, -1),\n",
        "            annot=True,\n",
        "            xticklabels=list(feature_flips.keys()),\n",
        "            yticklabels=[\"Instability\"],\n",
        "            cmap=\"coolwarm\",\n",
        "            ax=axes[3]\n",
        "        )\n",
        "    else:\n",
        "        axes[3].text(0.5, 0.5, \"No Instability Observed\", ha=\"center\", va=\"center\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    path = \"paper_ready_diagram.png\"\n",
        "    plt.savefig(path, dpi=300)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 4c. RADAR / SPIDER PLOT (IMPROVED)\n",
        "# =====================================\n",
        "def create_radar_plot(summary):\n",
        "    metrics = [\"Bias Risk Score (%)\", \"Decision Robustness Score\",\n",
        "               \"Decision Consistency Rate\", \"Entropy of Instability\", \"Max Feature Dominance\"]\n",
        "\n",
        "    values = [\n",
        "        summary.get(\"Bias Risk Score (%)\", 0),\n",
        "        summary.get(\"Decision Robustness Score\", 0),\n",
        "        summary.get(\"Decision Consistency Rate\", 0) * 100,\n",
        "        summary.get(\"Entropy of Instability\", 0) * 100,\n",
        "        summary.get(\"Max Feature Dominance\", 0) * 100\n",
        "    ]\n",
        "\n",
        "    # Close the loop\n",
        "    values += values[:1]\n",
        "    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()\n",
        "    angles += angles[:1]\n",
        "\n",
        "    plt.figure(figsize=(8,8))\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "\n",
        "    # Polygon & fill\n",
        "    ax.plot(angles, values, linewidth=3, linestyle='solid', color='teal', label=\"Metrics\")\n",
        "    ax.fill(angles, values, color='teal', alpha=0.25)\n",
        "\n",
        "    # Axis labels\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(metrics, fontsize=12, fontweight='bold')\n",
        "    ax.tick_params(axis='y', labelsize=10)\n",
        "    ax.set_rlabel_position(30)\n",
        "\n",
        "    # Grid\n",
        "    ax.grid(linewidth=1, linestyle='--', color='gray', alpha=0.7)\n",
        "\n",
        "    # Title\n",
        "    plt.title(\"AI Decision Robustness Radar Plot\", size=16, pad=20, fontweight='bold')\n",
        "\n",
        "    path = \"radar_plot.png\"\n",
        "    plt.tight_layout(pad=3)\n",
        "    plt.savefig(path, dpi=300)\n",
        "    plt.close()\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 5. PDF REPORT\n",
        "# =====================================\n",
        "def generate_pdf(summary, simple_exp, tech_exp, fii):\n",
        "    path = \"BIDeR_X_Audit_Report.pdf\"\n",
        "    doc = SimpleDocTemplate(path)\n",
        "    styles = getSampleStyleSheet()\n",
        "    elements = []\n",
        "\n",
        "    elements.append(Paragraph(\"<b>BIDeR-X Bias Audit Report</b>\", styles[\"Title\"]))\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "    for k, v in summary.items():\n",
        "        elements.append(Paragraph(f\"<b>{k}:</b> {v}\", styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Simple Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(simple_exp, styles[\"Normal\"]))\n",
        "\n",
        "    elements.append(Spacer(1, 12))\n",
        "    elements.append(Paragraph(\"<b>Technical Explanation</b>\", styles[\"Heading2\"]))\n",
        "    elements.append(Paragraph(tech_exp, styles[\"Normal\"]))\n",
        "\n",
        "    if fii:\n",
        "        table = [[\"Feature\", \"Feature Instability Index\"]] + list(fii.items())\n",
        "        elements.append(Spacer(1, 12))\n",
        "        elements.append(Table(table))\n",
        "\n",
        "    doc.build(elements)\n",
        "    return path\n",
        "\n",
        "# =====================================\n",
        "# 6. MAIN PIPELINE\n",
        "# =====================================\n",
        "def run_audit(system_type, n_cases, perturb, noise, iterations):\n",
        "    (\n",
        "        bias, ifvi, dcr, drs, ci_low, ci_high,\n",
        "        entropy, mfd, grade,\n",
        "        flips, fii, feature_importance,\n",
        "        synthetic_df, perturb_df, flips_df\n",
        "    ) = probe_bias(system_type, n_cases, perturb, noise, iterations)\n",
        "\n",
        "    simple_exp = f\"Decision changes occur {bias}% of the time for nearly identical individuals.\"\n",
        "    tech_exp = f\"IFVI={ifvi:.4f}, CI=[{ci_low},{ci_high}], Entropy={entropy}, MFD={mfd}, Grade={grade}\"\n",
        "\n",
        "    summary = {\n",
        "        \"Decision System\": system_type,\n",
        "        \"Bias Risk Score (%)\": bias,\n",
        "        \"IFVI\": round(ifvi, 4),\n",
        "        \"Decision Consistency Rate\": dcr,\n",
        "        \"Decision Robustness Score\": drs,\n",
        "        \"IFVI Confidence Interval\": f\"[{ci_low}, {ci_high}]\",\n",
        "        \"Entropy of Instability\": entropy,\n",
        "        \"Max Feature Dominance\": mfd,\n",
        "        \"Robustness Grade\": grade\n",
        "    }\n",
        "\n",
        "    heatmap = create_heatmap(flips)\n",
        "    interactive_plot = create_interactive_plot(flips)\n",
        "    paper_diagram = create_paper_diagram(synthetic_df, perturb_df, flips_df, flips)\n",
        "    radar_plot = create_radar_plot(summary)\n",
        "    pdf = generate_pdf(summary, simple_exp, tech_exp, fii)\n",
        "\n",
        "    feature_table = pd.DataFrame(feature_importance, columns=[\"Feature\", \"FII\"])\n",
        "\n",
        "    return (\n",
        "        pd.DataFrame([summary]),\n",
        "        simple_exp,\n",
        "        tech_exp,\n",
        "        feature_table,\n",
        "        heatmap,\n",
        "        pdf,\n",
        "        interactive_plot,\n",
        "        synthetic_df,\n",
        "        perturb_df,\n",
        "        flips_df,\n",
        "        paper_diagram,\n",
        "        radar_plot\n",
        "    )\n",
        "\n",
        "# =====================================\n",
        "# 7. GRADIO UI\n",
        "# =====================================\n",
        "with gr.Blocks(title=\"BIDeR-X\") as demo:\n",
        "    gr.Markdown(\"## ðŸ§  BIDeR-X: Black-Box Bias Discovery System\")\n",
        "\n",
        "    with gr.Row():\n",
        "        system = gr.Dropdown([\"College Admission\", \"Loan Approval\", \"Hiring\"])\n",
        "        n_cases = gr.Slider(100, 1000, 300, step=50, label=\"Cases per Iteration\")\n",
        "        perturb = gr.Slider(0.01, 0.2, 0.05, step=0.01, label=\"Perturbation Strength\")\n",
        "        noise = gr.Slider(0.0, 0.2, 0.05, step=0.01, label=\"Noise Level\")\n",
        "        iterations = gr.Slider(1, 10, 3, step=1, label=\"Iterations\")\n",
        "\n",
        "    run = gr.Button(\"Run Bias Audit\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Summary\"):\n",
        "            summary = gr.Dataframe()\n",
        "            simple_exp = gr.Textbox()\n",
        "            tech_exp = gr.Textbox()\n",
        "\n",
        "        with gr.Tab(\"Feature Analysis\"):\n",
        "            feature_table = gr.Dataframe()\n",
        "            heatmap = gr.Image()\n",
        "            interactive_plot = gr.File()\n",
        "\n",
        "        with gr.Tab(\"Synthetic Data\"):\n",
        "            synthetic_df = gr.Dataframe()\n",
        "            perturb_df = gr.Dataframe()\n",
        "            flips_df = gr.Dataframe()\n",
        "\n",
        "        with gr.Tab(\"Paper Diagram\"):\n",
        "            paper_diagram = gr.Image()\n",
        "\n",
        "        with gr.Tab(\"Radar / Metrics\"):\n",
        "            radar_img = gr.Image(label=\"Radar / Spider Plot\")\n",
        "\n",
        "        with gr.Tab(\"Report\"):\n",
        "            pdf = gr.File()\n",
        "\n",
        "    run.click(\n",
        "        run_audit,\n",
        "        inputs=[system, n_cases, perturb, noise, iterations],\n",
        "        outputs=[summary, simple_exp, tech_exp,\n",
        "                 feature_table, heatmap, pdf,\n",
        "                 interactive_plot, synthetic_df,\n",
        "                 perturb_df, flips_df, paper_diagram,\n",
        "                 radar_img]\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "URyc2O7MSZAi",
        "outputId": "379abd22-8975-47ec-f38f-96ba2e4c81e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bf0abe564ce5b2adff.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bf0abe564ce5b2adff.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}